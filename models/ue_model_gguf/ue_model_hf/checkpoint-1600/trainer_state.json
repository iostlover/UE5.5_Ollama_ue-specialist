{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.7837235228539576,
  "eval_steps": 500,
  "global_step": 1600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011148272017837236,
      "grad_norm": 0.4751695394515991,
      "learning_rate": 0.00019485714285714286,
      "loss": 2.4359,
      "step": 10
    },
    {
      "epoch": 0.022296544035674472,
      "grad_norm": 0.6239833235740662,
      "learning_rate": 0.00018914285714285715,
      "loss": 1.8352,
      "step": 20
    },
    {
      "epoch": 0.033444816053511704,
      "grad_norm": 0.47650662064552307,
      "learning_rate": 0.00018342857142857145,
      "loss": 1.5467,
      "step": 30
    },
    {
      "epoch": 0.044593088071348944,
      "grad_norm": 0.35705384612083435,
      "learning_rate": 0.0001777142857142857,
      "loss": 1.4204,
      "step": 40
    },
    {
      "epoch": 0.055741360089186176,
      "grad_norm": 0.39037179946899414,
      "learning_rate": 0.000172,
      "loss": 1.2818,
      "step": 50
    },
    {
      "epoch": 0.06688963210702341,
      "grad_norm": 0.25673121213912964,
      "learning_rate": 0.0001662857142857143,
      "loss": 1.2827,
      "step": 60
    },
    {
      "epoch": 0.07803790412486064,
      "grad_norm": 0.24404369294643402,
      "learning_rate": 0.00016057142857142857,
      "loss": 1.2043,
      "step": 70
    },
    {
      "epoch": 0.08918617614269789,
      "grad_norm": 0.36061063408851624,
      "learning_rate": 0.00015485714285714286,
      "loss": 1.2801,
      "step": 80
    },
    {
      "epoch": 0.10033444816053512,
      "grad_norm": 0.31011295318603516,
      "learning_rate": 0.00014914285714285713,
      "loss": 1.2115,
      "step": 90
    },
    {
      "epoch": 0.11148272017837235,
      "grad_norm": 0.25056055188179016,
      "learning_rate": 0.00014342857142857145,
      "loss": 1.2121,
      "step": 100
    },
    {
      "epoch": 0.12263099219620958,
      "grad_norm": 0.26200351119041443,
      "learning_rate": 0.00013771428571428572,
      "loss": 1.1744,
      "step": 110
    },
    {
      "epoch": 0.13377926421404682,
      "grad_norm": 0.2855994999408722,
      "learning_rate": 0.000132,
      "loss": 1.1743,
      "step": 120
    },
    {
      "epoch": 0.14492753623188406,
      "grad_norm": 0.2653762400150299,
      "learning_rate": 0.0001262857142857143,
      "loss": 1.2009,
      "step": 130
    },
    {
      "epoch": 0.15607580824972128,
      "grad_norm": 0.2968124449253082,
      "learning_rate": 0.00012057142857142858,
      "loss": 1.1905,
      "step": 140
    },
    {
      "epoch": 0.16722408026755853,
      "grad_norm": 0.2769000828266144,
      "learning_rate": 0.00011485714285714286,
      "loss": 1.1478,
      "step": 150
    },
    {
      "epoch": 0.17837235228539577,
      "grad_norm": 0.3694221079349518,
      "learning_rate": 0.00010914285714285715,
      "loss": 1.1495,
      "step": 160
    },
    {
      "epoch": 0.189520624303233,
      "grad_norm": 0.328858882188797,
      "learning_rate": 0.00010342857142857143,
      "loss": 1.179,
      "step": 170
    },
    {
      "epoch": 0.20066889632107024,
      "grad_norm": 0.24552035331726074,
      "learning_rate": 9.771428571428572e-05,
      "loss": 1.1841,
      "step": 180
    },
    {
      "epoch": 0.21181716833890746,
      "grad_norm": 0.26949068903923035,
      "learning_rate": 9.200000000000001e-05,
      "loss": 1.1755,
      "step": 190
    },
    {
      "epoch": 0.2229654403567447,
      "grad_norm": 0.2694395184516907,
      "learning_rate": 8.62857142857143e-05,
      "loss": 1.1661,
      "step": 200
    },
    {
      "epoch": 0.23411371237458195,
      "grad_norm": 0.37738674879074097,
      "learning_rate": 8.057142857142857e-05,
      "loss": 1.1672,
      "step": 210
    },
    {
      "epoch": 0.24526198439241917,
      "grad_norm": 0.3728129267692566,
      "learning_rate": 7.485714285714285e-05,
      "loss": 1.1504,
      "step": 220
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 0.3116298317909241,
      "learning_rate": 6.914285714285715e-05,
      "loss": 1.1796,
      "step": 230
    },
    {
      "epoch": 0.26755852842809363,
      "grad_norm": 0.3119954466819763,
      "learning_rate": 6.342857142857143e-05,
      "loss": 1.2339,
      "step": 240
    },
    {
      "epoch": 0.2787068004459309,
      "grad_norm": 0.3060837984085083,
      "learning_rate": 5.771428571428572e-05,
      "loss": 1.1653,
      "step": 250
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 0.31248196959495544,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 1.1622,
      "step": 260
    },
    {
      "epoch": 0.3010033444816054,
      "grad_norm": 0.3585197925567627,
      "learning_rate": 4.628571428571429e-05,
      "loss": 1.1303,
      "step": 270
    },
    {
      "epoch": 0.31215161649944256,
      "grad_norm": 0.3295173645019531,
      "learning_rate": 4.057142857142857e-05,
      "loss": 1.1839,
      "step": 280
    },
    {
      "epoch": 0.3232998885172798,
      "grad_norm": 0.33820608258247375,
      "learning_rate": 3.485714285714286e-05,
      "loss": 1.2253,
      "step": 290
    },
    {
      "epoch": 0.33444816053511706,
      "grad_norm": 0.38118839263916016,
      "learning_rate": 2.9142857142857146e-05,
      "loss": 1.199,
      "step": 300
    },
    {
      "epoch": 0.3455964325529543,
      "grad_norm": 0.38865843415260315,
      "learning_rate": 2.342857142857143e-05,
      "loss": 1.1533,
      "step": 310
    },
    {
      "epoch": 0.35674470457079155,
      "grad_norm": 0.3409697115421295,
      "learning_rate": 1.7714285714285713e-05,
      "loss": 1.1878,
      "step": 320
    },
    {
      "epoch": 0.36789297658862874,
      "grad_norm": 0.3050645887851715,
      "learning_rate": 1.2e-05,
      "loss": 1.095,
      "step": 330
    },
    {
      "epoch": 0.379041248606466,
      "grad_norm": 0.35087502002716064,
      "learning_rate": 6.285714285714287e-06,
      "loss": 1.1647,
      "step": 340
    },
    {
      "epoch": 0.39018952062430323,
      "grad_norm": 0.3488715589046478,
      "learning_rate": 5.714285714285715e-07,
      "loss": 1.1636,
      "step": 350
    },
    {
      "epoch": 0.4013377926421405,
      "grad_norm": 0.3428109884262085,
      "learning_rate": 9.742857142857143e-05,
      "loss": 1.144,
      "step": 360
    },
    {
      "epoch": 0.4124860646599777,
      "grad_norm": 0.30348411202430725,
      "learning_rate": 9.457142857142858e-05,
      "loss": 1.1886,
      "step": 370
    },
    {
      "epoch": 0.4236343366778149,
      "grad_norm": 0.3092152774333954,
      "learning_rate": 9.171428571428572e-05,
      "loss": 1.1681,
      "step": 380
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 0.35008183121681213,
      "learning_rate": 8.885714285714286e-05,
      "loss": 1.1532,
      "step": 390
    },
    {
      "epoch": 0.4459308807134894,
      "grad_norm": 0.3954507112503052,
      "learning_rate": 8.6e-05,
      "loss": 1.1729,
      "step": 400
    },
    {
      "epoch": 0.45707915273132665,
      "grad_norm": 0.39932921528816223,
      "learning_rate": 8.314285714285715e-05,
      "loss": 1.1741,
      "step": 410
    },
    {
      "epoch": 0.4682274247491639,
      "grad_norm": 0.3464517295360565,
      "learning_rate": 8.028571428571428e-05,
      "loss": 1.151,
      "step": 420
    },
    {
      "epoch": 0.4793756967670011,
      "grad_norm": 0.31352269649505615,
      "learning_rate": 7.742857142857143e-05,
      "loss": 1.1184,
      "step": 430
    },
    {
      "epoch": 0.49052396878483834,
      "grad_norm": 0.34086886048316956,
      "learning_rate": 7.457142857142856e-05,
      "loss": 1.1933,
      "step": 440
    },
    {
      "epoch": 0.5016722408026756,
      "grad_norm": 0.4108180105686188,
      "learning_rate": 7.171428571428572e-05,
      "loss": 1.1288,
      "step": 450
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.38363850116729736,
      "learning_rate": 6.885714285714286e-05,
      "loss": 1.1501,
      "step": 460
    },
    {
      "epoch": 0.5239687848383501,
      "grad_norm": 0.36226245760917664,
      "learning_rate": 6.6e-05,
      "loss": 1.1611,
      "step": 470
    },
    {
      "epoch": 0.5351170568561873,
      "grad_norm": 0.4257736802101135,
      "learning_rate": 6.314285714285715e-05,
      "loss": 1.1386,
      "step": 480
    },
    {
      "epoch": 0.5462653288740246,
      "grad_norm": 0.46871012449264526,
      "learning_rate": 6.028571428571429e-05,
      "loss": 1.1482,
      "step": 490
    },
    {
      "epoch": 0.5574136008918618,
      "grad_norm": 0.39793387055397034,
      "learning_rate": 5.742857142857143e-05,
      "loss": 1.1226,
      "step": 500
    },
    {
      "epoch": 0.568561872909699,
      "grad_norm": 0.4254060983657837,
      "learning_rate": 5.457142857142857e-05,
      "loss": 1.1452,
      "step": 510
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.37584930658340454,
      "learning_rate": 5.171428571428571e-05,
      "loss": 1.079,
      "step": 520
    },
    {
      "epoch": 0.5908584169453734,
      "grad_norm": 0.44975775480270386,
      "learning_rate": 4.885714285714286e-05,
      "loss": 1.1568,
      "step": 530
    },
    {
      "epoch": 0.6020066889632107,
      "grad_norm": 0.40024933218955994,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.1604,
      "step": 540
    },
    {
      "epoch": 0.6131549609810479,
      "grad_norm": 0.3963375985622406,
      "learning_rate": 4.314285714285715e-05,
      "loss": 1.1769,
      "step": 550
    },
    {
      "epoch": 0.6243032329988851,
      "grad_norm": 0.4443337023258209,
      "learning_rate": 4.028571428571429e-05,
      "loss": 1.1456,
      "step": 560
    },
    {
      "epoch": 0.6354515050167224,
      "grad_norm": 0.37714648246765137,
      "learning_rate": 3.742857142857143e-05,
      "loss": 1.1323,
      "step": 570
    },
    {
      "epoch": 0.6465997770345596,
      "grad_norm": 0.38038963079452515,
      "learning_rate": 3.4571428571428574e-05,
      "loss": 1.1227,
      "step": 580
    },
    {
      "epoch": 0.6577480490523969,
      "grad_norm": 0.4095481336116791,
      "learning_rate": 3.1714285714285715e-05,
      "loss": 1.1476,
      "step": 590
    },
    {
      "epoch": 0.6688963210702341,
      "grad_norm": 0.36608725786209106,
      "learning_rate": 2.885714285714286e-05,
      "loss": 1.1333,
      "step": 600
    },
    {
      "epoch": 0.6800445930880713,
      "grad_norm": 0.357453316450119,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.1419,
      "step": 610
    },
    {
      "epoch": 0.6911928651059086,
      "grad_norm": 0.36015915870666504,
      "learning_rate": 2.3142857142857145e-05,
      "loss": 1.1538,
      "step": 620
    },
    {
      "epoch": 0.7023411371237458,
      "grad_norm": 0.3436952233314514,
      "learning_rate": 2.0285714285714286e-05,
      "loss": 1.1102,
      "step": 630
    },
    {
      "epoch": 0.7134894091415831,
      "grad_norm": 0.4801092743873596,
      "learning_rate": 1.742857142857143e-05,
      "loss": 1.1501,
      "step": 640
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 0.3898613452911377,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 1.1442,
      "step": 650
    },
    {
      "epoch": 0.7357859531772575,
      "grad_norm": 0.4287874698638916,
      "learning_rate": 1.1714285714285715e-05,
      "loss": 1.1391,
      "step": 660
    },
    {
      "epoch": 0.7469342251950948,
      "grad_norm": 0.4412476420402527,
      "learning_rate": 8.857142857142857e-06,
      "loss": 1.1595,
      "step": 670
    },
    {
      "epoch": 0.758082497212932,
      "grad_norm": 0.4631650745868683,
      "learning_rate": 6e-06,
      "loss": 1.176,
      "step": 680
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.43004053831100464,
      "learning_rate": 3.1428571428571433e-06,
      "loss": 1.1572,
      "step": 690
    },
    {
      "epoch": 0.7803790412486065,
      "grad_norm": 0.3951342701911926,
      "learning_rate": 2.8571428571428575e-07,
      "loss": 1.105,
      "step": 700
    },
    {
      "epoch": 0.7915273132664437,
      "grad_norm": 0.43971768021583557,
      "learning_rate": 6.495238095238095e-05,
      "loss": 1.1105,
      "step": 710
    },
    {
      "epoch": 0.802675585284281,
      "grad_norm": 0.4305022954940796,
      "learning_rate": 6.304761904761906e-05,
      "loss": 1.1731,
      "step": 720
    },
    {
      "epoch": 0.8138238573021181,
      "grad_norm": 0.4144536852836609,
      "learning_rate": 6.114285714285714e-05,
      "loss": 1.1339,
      "step": 730
    },
    {
      "epoch": 0.8249721293199554,
      "grad_norm": 0.4822104871273041,
      "learning_rate": 5.923809523809524e-05,
      "loss": 1.1777,
      "step": 740
    },
    {
      "epoch": 0.8361204013377926,
      "grad_norm": 0.4152143597602844,
      "learning_rate": 5.7333333333333336e-05,
      "loss": 1.1502,
      "step": 750
    },
    {
      "epoch": 0.8472686733556298,
      "grad_norm": 0.40403446555137634,
      "learning_rate": 5.542857142857143e-05,
      "loss": 1.1411,
      "step": 760
    },
    {
      "epoch": 0.8584169453734671,
      "grad_norm": 0.47810980677604675,
      "learning_rate": 5.3523809523809534e-05,
      "loss": 1.1193,
      "step": 770
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 0.45923712849617004,
      "learning_rate": 5.161904761904762e-05,
      "loss": 1.12,
      "step": 780
    },
    {
      "epoch": 0.8807134894091416,
      "grad_norm": 0.36423370242118835,
      "learning_rate": 4.971428571428572e-05,
      "loss": 1.1371,
      "step": 790
    },
    {
      "epoch": 0.8918617614269788,
      "grad_norm": 0.40264156460762024,
      "learning_rate": 4.780952380952381e-05,
      "loss": 1.1202,
      "step": 800
    },
    {
      "epoch": 0.903010033444816,
      "grad_norm": 0.38108697533607483,
      "learning_rate": 4.59047619047619e-05,
      "loss": 1.1233,
      "step": 810
    },
    {
      "epoch": 0.9141583054626533,
      "grad_norm": 0.42900413274765015,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.1401,
      "step": 820
    },
    {
      "epoch": 0.9253065774804905,
      "grad_norm": 0.4308250844478607,
      "learning_rate": 4.20952380952381e-05,
      "loss": 1.1173,
      "step": 830
    },
    {
      "epoch": 0.9364548494983278,
      "grad_norm": 0.38600507378578186,
      "learning_rate": 4.01904761904762e-05,
      "loss": 1.1215,
      "step": 840
    },
    {
      "epoch": 0.947603121516165,
      "grad_norm": 0.3965108096599579,
      "learning_rate": 3.8285714285714286e-05,
      "loss": 1.141,
      "step": 850
    },
    {
      "epoch": 0.9587513935340022,
      "grad_norm": 0.46253395080566406,
      "learning_rate": 3.638095238095238e-05,
      "loss": 1.1078,
      "step": 860
    },
    {
      "epoch": 0.9698996655518395,
      "grad_norm": 0.4124089181423187,
      "learning_rate": 3.447619047619048e-05,
      "loss": 1.0675,
      "step": 870
    },
    {
      "epoch": 0.9810479375696767,
      "grad_norm": 0.4063121974468231,
      "learning_rate": 3.257142857142857e-05,
      "loss": 1.1027,
      "step": 880
    },
    {
      "epoch": 0.992196209587514,
      "grad_norm": 0.4761737287044525,
      "learning_rate": 3.066666666666667e-05,
      "loss": 1.1393,
      "step": 890
    },
    {
      "epoch": 1.0033444816053512,
      "grad_norm": 0.3576441705226898,
      "learning_rate": 2.876190476190476e-05,
      "loss": 1.0962,
      "step": 900
    },
    {
      "epoch": 1.0144927536231885,
      "grad_norm": 0.48953863978385925,
      "learning_rate": 2.6857142857142857e-05,
      "loss": 1.1181,
      "step": 910
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 0.44805485010147095,
      "learning_rate": 2.4952380952380956e-05,
      "loss": 1.1067,
      "step": 920
    },
    {
      "epoch": 1.0367892976588629,
      "grad_norm": 0.42670008540153503,
      "learning_rate": 2.304761904761905e-05,
      "loss": 1.1084,
      "step": 930
    },
    {
      "epoch": 1.0479375696767002,
      "grad_norm": 0.46828609704971313,
      "learning_rate": 2.1142857142857144e-05,
      "loss": 1.0862,
      "step": 940
    },
    {
      "epoch": 1.0590858416945372,
      "grad_norm": 0.4219174385070801,
      "learning_rate": 1.923809523809524e-05,
      "loss": 1.1189,
      "step": 950
    },
    {
      "epoch": 1.0702341137123745,
      "grad_norm": 0.44341787695884705,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 1.1264,
      "step": 960
    },
    {
      "epoch": 1.0813823857302118,
      "grad_norm": 0.45778700709342957,
      "learning_rate": 1.5428571428571428e-05,
      "loss": 1.127,
      "step": 970
    },
    {
      "epoch": 1.0925306577480491,
      "grad_norm": 0.4180893301963806,
      "learning_rate": 1.3523809523809525e-05,
      "loss": 1.1347,
      "step": 980
    },
    {
      "epoch": 1.1036789297658862,
      "grad_norm": 0.46085503697395325,
      "learning_rate": 1.161904761904762e-05,
      "loss": 1.0674,
      "step": 990
    },
    {
      "epoch": 1.1148272017837235,
      "grad_norm": 0.454015851020813,
      "learning_rate": 9.714285714285715e-06,
      "loss": 1.1005,
      "step": 1000
    },
    {
      "epoch": 1.1259754738015608,
      "grad_norm": 0.42299625277519226,
      "learning_rate": 7.80952380952381e-06,
      "loss": 1.1282,
      "step": 1010
    },
    {
      "epoch": 1.137123745819398,
      "grad_norm": 0.44753339886665344,
      "learning_rate": 5.904761904761905e-06,
      "loss": 1.0899,
      "step": 1020
    },
    {
      "epoch": 1.1482720178372352,
      "grad_norm": 0.414474755525589,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.1286,
      "step": 1030
    },
    {
      "epoch": 1.1594202898550725,
      "grad_norm": 0.41869625449180603,
      "learning_rate": 2.095238095238095e-06,
      "loss": 1.0881,
      "step": 1040
    },
    {
      "epoch": 1.1705685618729098,
      "grad_norm": 0.44927752017974854,
      "learning_rate": 1.9047619047619048e-07,
      "loss": 1.1138,
      "step": 1050
    },
    {
      "epoch": 1.1817168338907469,
      "grad_norm": 0.40862715244293213,
      "learning_rate": 4.8714285714285714e-05,
      "loss": 1.0803,
      "step": 1060
    },
    {
      "epoch": 1.1928651059085842,
      "grad_norm": 0.5460132956504822,
      "learning_rate": 4.728571428571429e-05,
      "loss": 1.0833,
      "step": 1070
    },
    {
      "epoch": 1.2040133779264215,
      "grad_norm": 0.5558187365531921,
      "learning_rate": 4.585714285714286e-05,
      "loss": 1.0983,
      "step": 1080
    },
    {
      "epoch": 1.2151616499442586,
      "grad_norm": 0.5122014284133911,
      "learning_rate": 4.442857142857143e-05,
      "loss": 1.0722,
      "step": 1090
    },
    {
      "epoch": 1.2263099219620959,
      "grad_norm": 0.5191577076911926,
      "learning_rate": 4.3e-05,
      "loss": 1.0958,
      "step": 1100
    },
    {
      "epoch": 1.2374581939799332,
      "grad_norm": 0.474992036819458,
      "learning_rate": 4.1571428571428575e-05,
      "loss": 1.0577,
      "step": 1110
    },
    {
      "epoch": 1.2486064659977703,
      "grad_norm": 0.4116155505180359,
      "learning_rate": 4.014285714285714e-05,
      "loss": 1.0844,
      "step": 1120
    },
    {
      "epoch": 1.2597547380156076,
      "grad_norm": 0.47989171743392944,
      "learning_rate": 3.8714285714285715e-05,
      "loss": 1.1336,
      "step": 1130
    },
    {
      "epoch": 1.2709030100334449,
      "grad_norm": 0.4936278462409973,
      "learning_rate": 3.728571428571428e-05,
      "loss": 1.1285,
      "step": 1140
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.46971556544303894,
      "learning_rate": 3.585714285714286e-05,
      "loss": 1.1129,
      "step": 1150
    },
    {
      "epoch": 1.2931995540691192,
      "grad_norm": 0.547156035900116,
      "learning_rate": 3.442857142857143e-05,
      "loss": 1.0806,
      "step": 1160
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 0.4900853931903839,
      "learning_rate": 3.3e-05,
      "loss": 1.094,
      "step": 1170
    },
    {
      "epoch": 1.3154960981047936,
      "grad_norm": 0.48972049355506897,
      "learning_rate": 3.1571428571428576e-05,
      "loss": 1.1146,
      "step": 1180
    },
    {
      "epoch": 1.326644370122631,
      "grad_norm": 0.46406054496765137,
      "learning_rate": 3.0142857142857146e-05,
      "loss": 1.147,
      "step": 1190
    },
    {
      "epoch": 1.3377926421404682,
      "grad_norm": 0.4248453974723816,
      "learning_rate": 2.8714285714285716e-05,
      "loss": 1.1231,
      "step": 1200
    },
    {
      "epoch": 1.3489409141583055,
      "grad_norm": 0.5138345956802368,
      "learning_rate": 2.7285714285714286e-05,
      "loss": 1.1102,
      "step": 1210
    },
    {
      "epoch": 1.3600891861761428,
      "grad_norm": 0.46919411420822144,
      "learning_rate": 2.5857142857142856e-05,
      "loss": 1.0864,
      "step": 1220
    },
    {
      "epoch": 1.37123745819398,
      "grad_norm": 0.48614397644996643,
      "learning_rate": 2.442857142857143e-05,
      "loss": 1.0711,
      "step": 1230
    },
    {
      "epoch": 1.3823857302118172,
      "grad_norm": 0.5135048031806946,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 1.1153,
      "step": 1240
    },
    {
      "epoch": 1.3935340022296545,
      "grad_norm": 0.4742237627506256,
      "learning_rate": 2.1571428571428574e-05,
      "loss": 1.0804,
      "step": 1250
    },
    {
      "epoch": 1.4046822742474916,
      "grad_norm": 0.5027904510498047,
      "learning_rate": 2.0142857142857144e-05,
      "loss": 1.0826,
      "step": 1260
    },
    {
      "epoch": 1.415830546265329,
      "grad_norm": 0.49653491377830505,
      "learning_rate": 1.8714285714285714e-05,
      "loss": 1.0882,
      "step": 1270
    },
    {
      "epoch": 1.4269788182831662,
      "grad_norm": 0.4451015293598175,
      "learning_rate": 1.7285714285714287e-05,
      "loss": 1.0675,
      "step": 1280
    },
    {
      "epoch": 1.4381270903010033,
      "grad_norm": 0.4750109910964966,
      "learning_rate": 1.5857142857142857e-05,
      "loss": 1.0808,
      "step": 1290
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 0.4498130977153778,
      "learning_rate": 1.442857142857143e-05,
      "loss": 1.1086,
      "step": 1300
    },
    {
      "epoch": 1.4604236343366779,
      "grad_norm": 0.551056444644928,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.0873,
      "step": 1310
    },
    {
      "epoch": 1.471571906354515,
      "grad_norm": 0.6094328761100769,
      "learning_rate": 1.1571428571428573e-05,
      "loss": 1.0695,
      "step": 1320
    },
    {
      "epoch": 1.4827201783723523,
      "grad_norm": 0.5106709599494934,
      "learning_rate": 1.0142857142857143e-05,
      "loss": 1.0586,
      "step": 1330
    },
    {
      "epoch": 1.4938684503901896,
      "grad_norm": 0.5033596158027649,
      "learning_rate": 8.714285714285715e-06,
      "loss": 1.1207,
      "step": 1340
    },
    {
      "epoch": 1.5050167224080266,
      "grad_norm": 0.534112811088562,
      "learning_rate": 7.285714285714286e-06,
      "loss": 1.0628,
      "step": 1350
    },
    {
      "epoch": 1.516164994425864,
      "grad_norm": 0.5461558699607849,
      "learning_rate": 5.857142857142857e-06,
      "loss": 1.0584,
      "step": 1360
    },
    {
      "epoch": 1.5273132664437012,
      "grad_norm": 0.4802360534667969,
      "learning_rate": 4.428571428571428e-06,
      "loss": 1.0921,
      "step": 1370
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.5485398173332214,
      "learning_rate": 3e-06,
      "loss": 1.0728,
      "step": 1380
    },
    {
      "epoch": 1.5496098104793758,
      "grad_norm": 0.5706371665000916,
      "learning_rate": 1.5714285714285717e-06,
      "loss": 1.0749,
      "step": 1390
    },
    {
      "epoch": 1.560758082497213,
      "grad_norm": 0.4519191384315491,
      "learning_rate": 1.4285714285714287e-07,
      "loss": 1.0612,
      "step": 1400
    },
    {
      "epoch": 1.57190635451505,
      "grad_norm": 0.53436279296875,
      "learning_rate": 4.292084726867336e-05,
      "loss": 1.0781,
      "step": 1410
    },
    {
      "epoch": 1.5830546265328875,
      "grad_norm": 0.4576030373573303,
      "learning_rate": 4.180602006688964e-05,
      "loss": 1.0288,
      "step": 1420
    },
    {
      "epoch": 1.5942028985507246,
      "grad_norm": 0.5499264597892761,
      "learning_rate": 4.069119286510591e-05,
      "loss": 1.135,
      "step": 1430
    },
    {
      "epoch": 1.605351170568562,
      "grad_norm": 0.4598093330860138,
      "learning_rate": 3.957636566332219e-05,
      "loss": 1.0892,
      "step": 1440
    },
    {
      "epoch": 1.6164994425863992,
      "grad_norm": 0.49277088046073914,
      "learning_rate": 3.846153846153846e-05,
      "loss": 1.1209,
      "step": 1450
    },
    {
      "epoch": 1.6276477146042363,
      "grad_norm": 0.5499263405799866,
      "learning_rate": 3.734671125975474e-05,
      "loss": 1.0881,
      "step": 1460
    },
    {
      "epoch": 1.6387959866220736,
      "grad_norm": 0.5110511183738708,
      "learning_rate": 3.6231884057971014e-05,
      "loss": 1.0734,
      "step": 1470
    },
    {
      "epoch": 1.649944258639911,
      "grad_norm": 0.5032190680503845,
      "learning_rate": 3.511705685618729e-05,
      "loss": 1.0798,
      "step": 1480
    },
    {
      "epoch": 1.661092530657748,
      "grad_norm": 0.49463599920272827,
      "learning_rate": 3.4002229654403564e-05,
      "loss": 1.0986,
      "step": 1490
    },
    {
      "epoch": 1.6722408026755853,
      "grad_norm": 0.5199068188667297,
      "learning_rate": 3.2887402452619846e-05,
      "loss": 1.1045,
      "step": 1500
    },
    {
      "epoch": 1.6833890746934226,
      "grad_norm": 0.5846657156944275,
      "learning_rate": 3.177257525083612e-05,
      "loss": 1.0927,
      "step": 1510
    },
    {
      "epoch": 1.6945373467112597,
      "grad_norm": 0.5787625908851624,
      "learning_rate": 3.06577480490524e-05,
      "loss": 1.0828,
      "step": 1520
    },
    {
      "epoch": 1.705685618729097,
      "grad_norm": 0.5389390587806702,
      "learning_rate": 2.9542920847268673e-05,
      "loss": 1.0872,
      "step": 1530
    },
    {
      "epoch": 1.7168338907469343,
      "grad_norm": 0.5123484134674072,
      "learning_rate": 2.8428093645484948e-05,
      "loss": 1.1033,
      "step": 1540
    },
    {
      "epoch": 1.7279821627647713,
      "grad_norm": 0.4662236273288727,
      "learning_rate": 2.731326644370123e-05,
      "loss": 1.1224,
      "step": 1550
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 0.5730407238006592,
      "learning_rate": 2.6198439241917505e-05,
      "loss": 1.0866,
      "step": 1560
    },
    {
      "epoch": 1.750278706800446,
      "grad_norm": 0.5284109115600586,
      "learning_rate": 2.508361204013378e-05,
      "loss": 1.1006,
      "step": 1570
    },
    {
      "epoch": 1.761426978818283,
      "grad_norm": 0.5617824196815491,
      "learning_rate": 2.3968784838350056e-05,
      "loss": 1.145,
      "step": 1580
    },
    {
      "epoch": 1.7725752508361206,
      "grad_norm": 0.5837791562080383,
      "learning_rate": 2.2853957636566335e-05,
      "loss": 1.1165,
      "step": 1590
    },
    {
      "epoch": 1.7837235228539576,
      "grad_norm": 0.47158458828926086,
      "learning_rate": 2.173913043478261e-05,
      "loss": 1.0728,
      "step": 1600
    }
  ],
  "logging_steps": 10,
  "max_steps": 1794,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.113677897638871e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
