# ğŸš€ UE5 Specialist - Ollama Model

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Ollama](https://img.shields.io/badge/Ollama-compatible-green.svg)](https://ollama.ai)

A specialized Unreal Engine 5 AI model for Ollama. Generate UE5 C++ code, analyze projects, and edit files with AI assistance.

Unreal Engine 5 ç‰¹åŒ–å‹ Ollama AI ãƒ¢ãƒ‡ãƒ«ã€‚UE5 C++ ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æã€ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†ãŒå¯èƒ½ã€‚

## âœ¨ Features

- **UE5 Specialized**: Trained on 28,703 UE5 C++ code samples
- **File Operations**: Read, create, and edit files directly  
- **Code Generation**: Generate UE5 C++ code from natural language
- **Interactive Agent**: File manipulation with AI assistance
- **Local Execution**: Runs completely offline - no internet required

## ğŸ“‹ System Requirements

- Windows, macOS, or Linux
- Python 3.8+
- 8GB RAM minimum (16GB recommended)
- GPU recommended (NVIDIA/AMD), CPU works too
- 10GB disk space

## ğŸš€ Quick Start (3 Steps)

### Step 1: Install Ollama

Download from https://ollama.ai

```bash
ollama --version
```

### Step 2: Clone Repository

```bash
git clone https://github.com/yourusername/UE5.5_Ollama_ue-specialist.git
cd UE5.5_Ollama_ue-specialist
```

### Step 3: Setup & Run

**Terminal 1:**
```bash
ollama serve
```

**Terminal 2:**
```bash
ollama create ue-specialist -f models/Modelfile
python agent/ue_agent.py
```

## ğŸ’» Usage Examples

### Generate Code
```bash
ğŸ‘¤ You: Create a PlayerController class with SetupPlayerInputComponent

ğŸ¤– UE5 Specialist: [Generates UE5 C++ code]
```

### Edit Files
```bash
ğŸ‘¤ You: read_file: C:\MyProject\Source\Character.h

ğŸ‘¤ You: write_file: C:\MyProject\Source\NewActor.cpp | [code]

ğŸ‘¤ You: replace_in_file: C:\MyProject\Source\Character.cpp | old | new
```

## ğŸ“š Documentation

### English
- **[README_EN.md](README_EN.md)** - Full English guide
- **[agent/UE_AGENT_README_EN.md](agent/UE_AGENT_README_EN.md)** - Agent usage (English)
- **[agent/FILE_EDITING_GUIDE_EN.md](agent/FILE_EDITING_GUIDE_EN.md)** - Command reference (English)

### æ—¥æœ¬èª
- **[README.md](README.md)** - å®Œå…¨ãªæ—¥æœ¬èªã‚¬ã‚¤ãƒ‰
- **[agent/UE_AGENT_README.md](agent/UE_AGENT_README.md)** - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½¿ç”¨æ–¹æ³•
- **[agent/FILE_EDITING_GUIDE.md](agent/FILE_EDITING_GUIDE.md)** - ã‚³ãƒãƒ³ãƒ‰ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

## ğŸ¯ Available Commands

```bash
# Read file or directory
read_file: C:\path\to\file.cpp

# List folder contents
list_directory: C:\path\to\folder

# Create or edit file
write_file: C:\path\to\file.cpp | #include "CoreMinimal.h"

# Replace text
replace_in_file: C:\path\to\file.cpp | old_text | new_text
```

## ğŸ”§ Troubleshooting

### Cannot connect to Ollama
```bash
ollama serve
```

### Out of Memory
```bash
ollama serve --num-gpu 0  # CPU only
```

### Model not found
```bash
ollama create ue-specialist -f models/Modelfile
```

## ğŸ“¦ What's Included

- âœ… `ue-specialist` model (4.7 GB)
- âœ… Python agent with file operations
- âœ… Complete documentation (English & Japanese)
- âœ… Examples and workflows

## ğŸ“Š Model Information

| Item | Details |
|------|---------|
| **Base Model** | Qwen2.5-Coder-7B |
| **Training Data** | 28,703 UE5 C++ samples + documentation |
| **Method** | QLoRA (4-bit quantization) |
| **Format** | GGUF (Ollama compatible) |
| **Size** | 4-7 GB |
| **Environment** | NVIDIA GPU 6GB+ or CPU |

## ğŸ“ License

MIT License - See LICENSE file

## ğŸ¤ Support

- ğŸ“– Check documentation first
- ğŸ› Found a bug? [Open an Issue](../../issues)
- ğŸ’¬ Have questions? [Discussions](../../discussions)

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai) - Local LLM runtime
- [Unsloth](https://github.com/unslothai/unsloth) - Fast fine-tuning
- [Qwen Team](https://github.com/QwenLM) - Base model

---

**Choose your language:**
- ğŸŒ [English Guide](README_EN.md)
- ğŸ‡¯ğŸ‡µ [æ—¥æœ¬èªã‚¬ã‚¤ãƒ‰](README.md)

â­ If this helps you, please consider giving it a Star!
